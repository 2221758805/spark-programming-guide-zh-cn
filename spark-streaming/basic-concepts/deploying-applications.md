# 部署应用程序

Spark Streaming应用程序部署到集群中的方式和其他Spark程序是一样的。请参考[部署指南](../../deploying/README.md)了解更多信息。

需要注意的是，用到[高级源](input-DStreams.md)的应用程序在部署时需要将外部的组件(artifact)以及依赖的包打包进应用程序。例如，用到`TwitterUtils`的应用程序，需要将
`spark-streaming-twitter_2.10`及其依赖的包打包进应用程序。

如果运行的Spark Streaming应用程序需要升级，有两种可能的方法

- 启动升级的应用程序，使其与未升级的应用程序并行运行。一旦新的程序（与就程序接收相同的数据）已经准备就绪，旧的应用程序就可以关闭。这种方法支持将数据发送到两个不同的目的地（新程序一个，旧程序一个）
- 首先，平滑的关闭（`StreamingContext.stop(...)`或`JavaStreamingContext.stop(...)`）现有的应用程序。在关闭之前，要保证已经接收的数据完全处理完。然后，就可以启动升级的应用程序，升级
的应用程序会接着旧应用程序的点开始处理。这种方法仅支持具有源端缓存功能的输入源（如flume，kafka），这是因为当旧的应用程序已经关闭，升级的应用程序还没有启动的时候，数据需要被缓存。

